{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8e26fa-b364-4598-96af-1dbeee0d06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59290b69-0de7-4486-8d32-01c9fa55ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from PIL import Image, ImageFile\n",
    "import torch, torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as tf\n",
    "from transformers import AutoModelForImageClassification\n",
    "from datasets import load_from_disk\n",
    "from fastprogress import progress_bar as pb\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a01f308-ebc5-4c69-9a7b-9472bc7953d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms = {key:{} for key in [224, 256]}\n",
    "datasets = {}\n",
    "\n",
    "def train_transform_224(ex):\n",
    "    if \"pixel_values\" in ex:\n",
    "        ex[\"pixel_values\"]=[transforms[224][\"train\"](image) for image in ex[\"pixel_values\"]]\n",
    "    return ex\n",
    "def test_transform_224(ex):\n",
    "    if \"pixel_values\" in ex:\n",
    "        ex[\"pixel_values\"]=[transforms[224][\"test\"](image) for image in ex[\"pixel_values\"]]\n",
    "    return ex\n",
    "def train_transform_256(ex):\n",
    "    if \"pixel_values\" in ex:\n",
    "        ex[\"pixel_values\"]=[transforms[256][\"train\"](image) for image in ex[\"pixel_values\"]]\n",
    "    return ex\n",
    "def test_transform_256(ex):\n",
    "    if \"pixel_values\" in ex:\n",
    "        ex[\"pixel_values\"]=[transforms[256][\"test\"](image) for image in ex[\"pixel_values\"]]\n",
    "    return ex\n",
    "\n",
    "for size in [224, 256]:\n",
    "    transforms[size][\"train\"] = tf.Compose([\n",
    "        tf.ToImage(),\n",
    "        tf.ToDtype(torch.float32, scale=True),\n",
    "        tf.RandomRotation(degrees=20),\n",
    "        tf.RandomHorizontalFlip(),\n",
    "        tf.RandomResizedCrop(size=(size,size), scale=(.8,1.0), antialias=True),\n",
    "        tf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    transforms[size][\"test\"] = tf.Compose([\n",
    "        tf.ToImage(),\n",
    "        tf.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "        tf.Resize(size=(size,size)),\n",
    "        tf.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    dataset=load_from_disk(\"./data/dataset/\")\n",
    "    dataset[\"train\"].set_format(\"torch\")\n",
    "    dataset[\"test\"].set_format(\"torch\")\n",
    "    dataset[\"train\"]=dataset[\"train\"].rename_column(\"image\",\"pixel_values\")\n",
    "    dataset[\"test\"]=dataset[\"test\"].rename_column(\"image\",\"pixel_values\")\n",
    "    datasets[size]=dataset\n",
    "\n",
    "datasets[224][\"train\"].set_transform(train_transform_224)\n",
    "datasets[224][\"test\"].set_transform(train_transform_224)\n",
    "datasets[256][\"train\"].set_transform(train_transform_256)\n",
    "datasets[256][\"test\"].set_transform(train_transform_256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3166623-af46-48da-9b15-5c94aa5ac063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26be8056-6bc6-4dc0-9d8d-e44787a93753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets[256] #default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f7100bb-089e-4164-aedb-4bacd934e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[224][\"train\"][0][\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f62fcd6-49b1-4f05-a899-65c82ff8c2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[256][\"train\"][0][\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7a1453-aab3-4449-ae49-a6848d38b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather training data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61dd0f5f-40ca-4cf2-b97f-f7a861e4f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=torch.tensor(dataset[\"train\"][\"labels\"])\n",
    "y_test=torch.tensor(dataset[\"test\"][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46bdb47-8b15-4cdf-ad6d-ee00c2e31d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total=torch.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb7720d3-4d59-4c8b-9865-2367d05bacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=dataset[\"test\"].features[\"labels\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73db5b2-1ad4-41ec-943d-18713091ad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b147cf76-a249-4e35-96fd-f2b59f434471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list={\n",
    "    \"mirluvams/swinv2-base-patch4-window16-256-popocatepetl\":256,\n",
    "    #\"mirluvams/swinv2-tiny-patch4-window16-256-popocatepetl\":256,\n",
    "    #\"mirluvams/beit-base-patch16-224-popocatepetl\":224,\n",
    "    #\"mirluvams/vit-base-patch16-224-popocatepetl\":224,\n",
    "}\n",
    "y_pred = {}\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5677f613-eac6-4e8a-bad8-2be257fba37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6fb0a4650d4a59aecf9bef092beeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4736e51eb462464eb422b935aefbcdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/348M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating mirluvams/swinv2-base-patch4-window16-256-popocatepetl\n",
      "Train data (100.00%)\r"
     ]
    }
   ],
   "source": [
    "BS=8\n",
    "for model_name, size in model_list.items():\n",
    "    model=AutoModelForImageClassification.from_pretrained(model_name).to(DEVICE)\n",
    "    print(\"Evaluating\",model_name)\n",
    "    \n",
    "    test_outputs=[]\n",
    "    print(\"Test data\", end=\"\\r\")\n",
    "    count=0\n",
    "    for batch in datasets[size][\"test\"].iter(BS):\n",
    "        output=model(torch.stack(batch[\"pixel_values\"]).to(DEVICE))\n",
    "        output=output.logits.detach().cpu().argmax(1) #remove gradient, take out of GPU, get highest value index\n",
    "        test_outputs+=output.tolist()\n",
    "        count+=len(batch[\"pixel_values\"])\n",
    "        print(f'Test data ({count/len(datasets[size][\"test\"])*100:.02f}%)', end=\"\\r\")\n",
    "\n",
    "    train_outputs=[]\n",
    "    print(\"Train data\", end=\"\\r\")\n",
    "    count=0\n",
    "    for batch in datasets[size][\"train\"].iter(BS):\n",
    "        output=model(torch.stack(batch[\"pixel_values\"]).to(DEVICE))\n",
    "        output=output.logits.detach().cpu().argmax(1)\n",
    "        train_outputs+=output.tolist()\n",
    "        count+=len(batch[\"pixel_values\"])\n",
    "        print(f'Train data ({count/len(datasets[size][\"train\"])*100:.02f}%)', end=\"\\r\")\n",
    "    total_outputs=train_outputs+test_outputs\n",
    "\n",
    "    y_pred[model_name]={}\n",
    "    y_pred[model_name][\"train\"]=train_outputs\n",
    "    y_pred[model_name][\"test\"]=test_outputs\n",
    "    y_pred[model_name][\"total\"]=total_outputs\n",
    "    \n",
    "    model=None\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdc7cf-37b5-43c8-965b-37a9f3c09dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a20cf506-cd72-4e9b-9169-1f02c44565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean_train=np.unique(datasets[256][\"train\"][\"labels\"],return_counts=True)[1].argmax() #class that repeats the most\n",
    "n_train=len(datasets[256][\"train\"])\n",
    "n_test=len(datasets[256][\"test\"])\n",
    "y_pred[\"y_mean\"]={}\n",
    "y_pred[\"y_mean\"][\"train\"]=list(np.full(n_train, y_mean_train))\n",
    "y_pred[\"y_mean\"][\"test\"]=list(np.full(n_test, y_mean_train))\n",
    "y_pred[\"y_mean\"][\"total\"]=list(np.full(n_train+n_test, y_mean_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d99e993-2f53-4d09-870d-e05e5790b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_median_train=np.median(datasets[256][\"train\"][\"labels\"])\n",
    "n_train=len(datasets[256][\"train\"])\n",
    "n_test=len(datasets[256][\"test\"])\n",
    "y_pred[\"y_median\"]={}\n",
    "y_pred[\"y_median\"][\"train\"]=list(np.full(n_train, y_median_train))\n",
    "y_pred[\"y_median\"][\"test\"]=list(np.full(n_test, y_median_train))\n",
    "y_pred[\"y_median\"][\"total\"]=list(np.full(n_train+n_test, y_median_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c7579c-b0f8-4212-8459-33ded486217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate standard metrics for classification predictors\n",
    "def compute_metrics(y,y_p):\n",
    "    return {\n",
    "        \"report\":sklearn.metrics.classification_report(y,y_p, target_names=labels, output_dict=True, zero_division=0),\n",
    "        \"matrix\":sklearn.metrics.confusion_matrix(y,y_p),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b621d9-0c41-4462-903d-99c0d7ca0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics={}\n",
    "for model_name, m_dict in y_pred.items():\n",
    "    metrics[model_name]={}\n",
    "    metrics[model_name][\"train\"]=compute_metrics(y_train, m_dict[\"train\"])\n",
    "    metrics[model_name][\"test\"]=compute_metrics(y_test, m_dict[\"test\"])\n",
    "    metrics[model_name][\"total\"]=compute_metrics(y_total, m_dict[\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2ba11-ced0-4c43-9377-a301b0f17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics[\"mirluvams/swinv2-base-patch4-window16-256-popocatepetl\"][\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c710dc-2a45-4ce9-9582-7b0c8dae4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf report | model slice i_p i_r i_f1 i_s ... fe_f1 fe_s acc m_p .. m_f1 w_p .. w_f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "292bfe27-d134-48b7-b3f3-831e8f4645c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixes=[]\n",
    "results=[]\n",
    "for model_name, slices in metrics.items():\n",
    "    for _slice, data in slices.items():\n",
    "        matrixes.append(pd.Series({\n",
    "            \"MODEL\":model_name,\n",
    "            \"SLICE\":_slice,\n",
    "            \"MATRIX\":data[\"matrix\"].flatten().tolist()\n",
    "        }))\n",
    "        data=data[\"report\"]\n",
    "        r_data={\n",
    "            \"MODEL\":model_name,\n",
    "            \"SLICE\":_slice,\n",
    "            #\"ACCURACY\":data[\"accuracy\"]\n",
    "        }\n",
    "        data[\"MACRO_AVG\"]=data[\"macro avg\"]\n",
    "        data[\"WEIGHTED_AVG\"]=data[\"weighted avg\"]\n",
    "        #for label in [\"INACTIVE\", \"WITH_EXPLOSION\", \"WITH_FUME\", \"WITH_FUME_AND_EXPLOSION\", \"MACRO_AVG\", \"WEIGHTED_AVG\"]:\n",
    "        #    r_data[label+\"_PRECISION\"]=data[label][\"precision\"]\n",
    "        #    r_data[label+\"_RECALL\"]=data[label][\"recall\"]\n",
    "        #    r_data[label+\"_F1\"]=data[label][\"f1-score\"]\n",
    "        #    r_data[label+\"_SUPPORT\"]=data[label][\"support\"]\n",
    "        \n",
    "        for label in [\"INACTIVO\", \"FUMAROLA\", \"ERUPCION\", \"MACRO_AVG\", \"WEIGHTED_AVG\"]:\n",
    "            for metric in [\"precision\", \"recall\", \"f1-score\", \"support\"]:\n",
    "                m_data=r_data.copy()\n",
    "                m_data[\"METRIC\"]=metric.upper()\n",
    "                m_data[\"CLASS\"]=label\n",
    "                m_data[\"VALUE\"]=data[label][metric]\n",
    "                results.append(pd.Series(m_data))\n",
    "        m_data=r_data.copy()\n",
    "        m_data[\"METRIC\"]=\"ACCURACY\"\n",
    "        m_data[\"CLASS\"]=\"GENERAL\"\n",
    "        m_data[\"VALUE\"]=data[\"accuracy\"]\n",
    "        results.append(pd.Series(m_data))\n",
    "matrixes=pd.DataFrame(matrixes)\n",
    "matrixes.to_feather(\"data/confusion_matrixes.feather\")\n",
    "results=pd.DataFrame(results)\n",
    "results.to_feather(\"data/results.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4c085e7-e1c8-4b64-b125-c31cca573f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SLICE</th>\n",
       "      <th>MATRIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>[1016, 13, 1, 10, 7373, 144, 2, 67, 6041]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>test</td>\n",
       "      <td>[90, 19, 5, 12, 743, 82, 1, 69, 609]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>total</td>\n",
       "      <td>[1106, 32, 6, 22, 8116, 226, 3, 136, 6650]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y_mean</td>\n",
       "      <td>train</td>\n",
       "      <td>[0, 1030, 0, 0, 7527, 0, 0, 6110, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y_mean</td>\n",
       "      <td>test</td>\n",
       "      <td>[0, 114, 0, 0, 837, 0, 0, 679, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y_mean</td>\n",
       "      <td>total</td>\n",
       "      <td>[0, 1144, 0, 0, 8364, 0, 0, 6789, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>y_median</td>\n",
       "      <td>train</td>\n",
       "      <td>[0, 1030, 0, 0, 7527, 0, 0, 6110, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y_median</td>\n",
       "      <td>test</td>\n",
       "      <td>[0, 114, 0, 0, 837, 0, 0, 679, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>[0, 1144, 0, 0, 8364, 0, 0, 6789, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MODEL  SLICE  \\\n",
       "0  mirluvams/swinv2-base-patch4-window16-256-popo...  train   \n",
       "1  mirluvams/swinv2-base-patch4-window16-256-popo...   test   \n",
       "2  mirluvams/swinv2-base-patch4-window16-256-popo...  total   \n",
       "3                                             y_mean  train   \n",
       "4                                             y_mean   test   \n",
       "5                                             y_mean  total   \n",
       "6                                           y_median  train   \n",
       "7                                           y_median   test   \n",
       "8                                           y_median  total   \n",
       "\n",
       "                                       MATRIX  \n",
       "0   [1016, 13, 1, 10, 7373, 144, 2, 67, 6041]  \n",
       "1        [90, 19, 5, 12, 743, 82, 1, 69, 609]  \n",
       "2  [1106, 32, 6, 22, 8116, 226, 3, 136, 6650]  \n",
       "3        [0, 1030, 0, 0, 7527, 0, 0, 6110, 0]  \n",
       "4           [0, 114, 0, 0, 837, 0, 0, 679, 0]  \n",
       "5        [0, 1144, 0, 0, 8364, 0, 0, 6789, 0]  \n",
       "6        [0, 1030, 0, 0, 7527, 0, 0, 6110, 0]  \n",
       "7           [0, 114, 0, 0, 837, 0, 0, 679, 0]  \n",
       "8        [0, 1144, 0, 0, 8364, 0, 0, 6789, 0]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6d75fba-ac02-42f0-843c-24f571f3feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SLICE</th>\n",
       "      <th>METRIC</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>PRECISION</td>\n",
       "      <td>INACTIVO</td>\n",
       "      <td>0.988327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>INACTIVO</td>\n",
       "      <td>0.986408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>F1-SCORE</td>\n",
       "      <td>INACTIVO</td>\n",
       "      <td>0.987366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>INACTIVO</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mirluvams/swinv2-base-patch4-window16-256-popo...</td>\n",
       "      <td>train</td>\n",
       "      <td>PRECISION</td>\n",
       "      <td>FUMAROLA</td>\n",
       "      <td>0.989266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>PRECISION</td>\n",
       "      <td>WEIGHTED_AVG</td>\n",
       "      <td>0.263398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>WEIGHTED_AVG</td>\n",
       "      <td>0.513223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>F1-SCORE</td>\n",
       "      <td>WEIGHTED_AVG</td>\n",
       "      <td>0.348129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>WEIGHTED_AVG</td>\n",
       "      <td>16297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>y_median</td>\n",
       "      <td>total</td>\n",
       "      <td>ACCURACY</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>0.513223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MODEL  SLICE     METRIC  \\\n",
       "0    mirluvams/swinv2-base-patch4-window16-256-popo...  train  PRECISION   \n",
       "1    mirluvams/swinv2-base-patch4-window16-256-popo...  train     RECALL   \n",
       "2    mirluvams/swinv2-base-patch4-window16-256-popo...  train   F1-SCORE   \n",
       "3    mirluvams/swinv2-base-patch4-window16-256-popo...  train    SUPPORT   \n",
       "4    mirluvams/swinv2-base-patch4-window16-256-popo...  train  PRECISION   \n",
       "..                                                 ...    ...        ...   \n",
       "184                                           y_median  total  PRECISION   \n",
       "185                                           y_median  total     RECALL   \n",
       "186                                           y_median  total   F1-SCORE   \n",
       "187                                           y_median  total    SUPPORT   \n",
       "188                                           y_median  total   ACCURACY   \n",
       "\n",
       "            CLASS         VALUE  \n",
       "0        INACTIVO      0.988327  \n",
       "1        INACTIVO      0.986408  \n",
       "2        INACTIVO      0.987366  \n",
       "3        INACTIVO   1030.000000  \n",
       "4        FUMAROLA      0.989266  \n",
       "..            ...           ...  \n",
       "184  WEIGHTED_AVG      0.263398  \n",
       "185  WEIGHTED_AVG      0.513223  \n",
       "186  WEIGHTED_AVG      0.348129  \n",
       "187  WEIGHTED_AVG  16297.000000  \n",
       "188       GENERAL      0.513223  \n",
       "\n",
       "[189 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b3f17ea-4215-48c5-a776-391195091919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_archives={\n",
    "    \"mirluvams/swinv2-base-patch4-window16-256-popocatepetl\":\"/home/miriam/tmp/models/swinv2-base/trainer_state.json\",\n",
    "    #\"mirluvams/swinv2-tiny-patch4-window16-256-popocatepetl\":\"/home/miriam/tmp/models/swinv2-tiny/trainer_state.json\",\n",
    "    #\"mirluvams/beit-base-patch16-224-popocatepetl\":\"/home/miriam/tmp/models/beit-base/trainer_state.json\",\n",
    "    #\"mirluvams/vit-base-patch16-224-popocatepetl\":\"/home/miriam/tmp/models/vit-base/trainer_state.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aa4d4ff-f269-4510-9805-9094c3a41563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data=[]\n",
    "for model_name, model_archive in model_archives.items():\n",
    "    with open(model_archive, \"r\") as f:\n",
    "        d = json.load(f)[\"log_history\"] #isolate logs\n",
    "        tmp=None\n",
    "        for step in d[:-1]: #skip conflicting line at end\n",
    "            is_eval=\"eval_f1\" in step.keys()\n",
    "            if not is_eval:\n",
    "                tmp={\n",
    "                    \"MODEL\":model_name,\n",
    "                    \"EPOCH\":step[\"epoch\"],\n",
    "                    \"GRAD_NORM\":step[\"grad_norm\"],\n",
    "                    \"LR\":step[\"learning_rate\"],\n",
    "                    \"TRAIN_LOSS\":step[\"loss\"],\n",
    "                    \"STEP\":step[\"step\"],\n",
    "                }\n",
    "            else:\n",
    "                tmp[\"EVAL_ACCURACY\"]=step[\"eval_accuracy\"]\n",
    "                tmp[\"EVAL_F1\"]=step[\"eval_f1\"]\n",
    "                tmp[\"EVAL_LOSS\"]=step[\"eval_loss\"]\n",
    "                data.append(pd.Series(tmp))\n",
    "                tmp=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680dd450-925d-4f6e-bac1-69a708f3eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=pd.DataFrame(data)\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3626496d-42bb-4fda-aff5-535af053a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.to_feather(\"data/training_logs.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a8669-a932-4ceb-a8ed-b709c97283bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781742e-33f3-43ac-a32e-d81dcd9a7a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945006cf-a31a-4541-98be-a02fcbd83330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
