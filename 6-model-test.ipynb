{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c449deb-1f01-472c-8862-f5e8c6e9f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda\"\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoImageProcessor, PreTrainedModel, PretrainedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcc4007-d68b-4d79-b3b0-b9ac750fc92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMultiRegressionConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_size=3,\n",
    "        init_checkpoint=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.output_size=output_size\n",
    "        self.init_checkpoint=init_checkpoint\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "class ImageMultiRegressionModel(PreTrainedModel):\n",
    "    config_class=ImageMultiRegressionConfig\n",
    "    def __init__(self, config, loss=nn.MSELoss()):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.inner_model = AutoModel.from_pretrained(config.init_checkpoint)\n",
    "        self.classifier = nn.Linear(self.inner_model.config.hidden_size, config.output_size)\n",
    "        self.loss=loss\n",
    "    \n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.inner_model(pixel_values=pixel_values)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # image embedding\n",
    "        values = self.classifier(cls_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss(values.view(-1), labels.view(-1))\n",
    "        return (loss, values) if loss is not None else values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4c7c9d-75fa-41a4-8d8f-c7252961d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset=load_from_disk(\"./data/dataset/\")\n",
    "dataset[\"train\"].set_format(\"torch\")\n",
    "dataset[\"test\"].set_format(\"torch\")\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch\n",
    "\n",
    "_train_transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(size=(256,256), scale=(.6,1.0), antialias=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def train_transform(ex):\n",
    "    if \"image\" in ex:\n",
    "        ex[\"pixel_values\"]=[_train_transform(image) for image in ex[\"image\"]]\n",
    "    return ex\n",
    "    \n",
    "_test_transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "    transforms.Resize(size=(256,256)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def test_transform(ex):\n",
    "    if \"image\" in ex:\n",
    "        ex[\"pixel_values\"]=[_test_transform(image) for image in ex[\"image\"]]\n",
    "    return ex\n",
    "\n",
    "dataset[\"train\"].set_transform(train_transform)\n",
    "dataset[\"test\"].set_transform(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b2301-e488-44ee-aa78-bde545a72e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be8056-6bc6-4dc0-9d8d-e44787a93753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7a1453-aab3-4449-ae49-a6848d38b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather training data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61dd0f5f-40ca-4cf2-b97f-f7a861e4f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.tensor(dataset[\"train\"][\"light_level\"])\n",
    "t2=torch.tensor(dataset[\"train\"][\"fume_strength\"])\n",
    "t3=torch.tensor(dataset[\"train\"][\"explosion_strength\"])\n",
    "ty=torch.tensor(dataset[\"train\"][\"class\"])\n",
    "T=torch.stack([t1,t2,t3], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0d3470-a81c-4fb5-b97b-ac89027562c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather target statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c9c912-e692-4b3a-ae87-d431d795258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=torch.tensor(dataset[\"test\"][\"light_level\"])\n",
    "y2=torch.tensor(dataset[\"test\"][\"fume_strength\"])\n",
    "y3=torch.tensor(dataset[\"test\"][\"explosion_strength\"])\n",
    "yy=torch.tensor(dataset[\"test\"][\"class\"])\n",
    "Y=torch.stack([y1,y2,y3], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84bb5a1-619f-4d74-b2cd-0238549bd5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of sample R score\n",
    "# https://stats.stackexchange.com/questions/228540/how-to-calculate-out-of-sample-r-squared/492581#492581\n",
    "# https://arxiv.org/pdf/2302.05131\n",
    "def oosR(MST, MSE): \n",
    "    return 1-MSE/MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9298ed2c-32bb-4c41-ad47-0bd41f21124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_MSE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b02a922-8e93-48f0-8197-a20bac96842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate standard metrics for regression predictors\n",
    "def compute_metrics_reg(x,y):\n",
    "    MSE=sklearn.metrics.mean_squared_error(x, y)\n",
    "    return {\"MSE\":MSE,\n",
    "           \"MAE\":sklearn.metrics.mean_absolute_error(x,y),\n",
    "           \"R2_test\":sklearn.metrics.r2_score(x,y),\n",
    "           \"oosR2\":0 if null_MSE==0 else oosR(null_MSE,MSE),\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c7579c-b0f8-4212-8459-33ded486217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate standard metrics for regression predictors\n",
    "def compute_metrics_class(x,y):\n",
    "    report=sklearn.metrics.classification_report(x,y, output_dict=True)\n",
    "    matrix=sklearn.metrics.confusion_matrix(x,y)\n",
    "    return report, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edc182-81b1-48c0-bd9b-1c5c3d0c8a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3d0b2-9659-45d0-9ab4-95427f5f9c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68cd1721-8441-4915-869f-c66ecff95451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: always predict the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8e0df8-58e8-4d5c-ba43-c1c4b427d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_mean=T.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fb3e3f-a445-4f10-b687-e16f33e614c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_mean_only = T_mean.repeat(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db11fb7f-1d7f-4783-9deb-4babb0ec7d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1891, 3]), torch.Size([1891, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_mean_only.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca369593-f7e8-42b1-944c-028bd5bfa1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9057, 0.7516, 0.3702])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_mean_only[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b9c5a4c-3f2b-4e0e-8afc-084678bf0ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.14325829, 'MAE': 0.31039932, 'R2_test': 0.0, 'oosR2': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics = compute_metrics_reg(T_mean_only, Y); mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb88a5d-a7be-4562-ac21-4e6ad0d3229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_MSE=mean_metrics[\"MSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521d9fb9-92c4-40c2-b612-3d861d0dd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: always predict the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eecc39f7-7812-46a0-9e51-b1ca3f7590b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_median=T.median(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3ac38e2-8b64-4a5e-b5f3-e2cfe4e8293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_median_only = T_median.repeat(Y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3673ade7-6453-4309-9076-f589248f3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1891, 3]), torch.Size([1891, 3]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_median_only.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11252f9-de92-4389-886a-244a3bb69cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_median_only[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c8a69d-1ee6-4375-aaec-2ca466c25505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21269357,\n",
       " 'MAE': 0.23851593,\n",
       " 'R2_test': 0.0,\n",
       " 'oosR2': -0.484686017036438}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_metrics = compute_metrics_reg(T_median_only, Y); median_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3decc-27b5-4c7f-9d7b-6b760f140388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deb04d11-22ce-4f14-9682-89656bb6aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.630903729921912"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosR(mean_metrics['MSE'], 0.052876099944114685) #swinv2-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043ce240-cb71-43fc-8f00-452f416c0d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4809130549607282"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosR(mean_metrics['MSE'], 0.07436350733041763) #dinov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed2b26c4-c895-4148-ae14-3f5ec9733ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383374449144006"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosR(mean_metrics['MSE'], 0.051811158657073975) #beit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e98164a1-f445-43c9-b735-75c139a6724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import progress_bar as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2c1ffee-eb55-400c-a4be-736f3d313eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b307464-4dda-4f82-9078-17a6a14a33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reg(model):\n",
    "    outputs=[]\n",
    "    for batch in pb(dataset[\"test\"]):\n",
    "        output=model(batch[\"pixel_values\"][None,:,:,:].to(DEVICE)).cpu()\n",
    "        outputs.append(output)\n",
    "    print(torch.stack(outputs))\n",
    "    return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "147e87bd-d784-4da5-b1b5-164135cb923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12' class='' max='1891' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.63% [12/1891 00:11&lt;29:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results: regression models\n",
    "\n",
    "reg_model_paths=[\"models/swinv2-base\", ]\n",
    "reg_models=[ImageMultiRegressionModel.from_pretrained(model).to(DEVICE) for model in reg_model_paths]\n",
    "reg_results=[evaluate_reg(model) for model in reg_models]\n",
    "reg_scores=[compute_metrics_reg() for results in reg_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76fe8e-57b8-44ec-ae9d-b0ff0f90044e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11700aac-6f54-4d0d-9198-355a9a0a9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results: regression models translated to classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d4ec5-60d3-4060-87d9-fb397d087d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results: (older) classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05951759-cecb-4fe8-87b1-4dc0c063718a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
